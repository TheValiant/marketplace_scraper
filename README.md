# ecom_search

A modular, local e-commerce price comparison engine for UAE markets. Search across multiple marketplaces simultaneously, filter out noise, compare prices, and export results â€” all from a rich Terminal User Interface.

> **Core Philosophy**: *"Resilience over Speed."* The engine prioritizes anti-detection and stability over raw scraping throughput.

## Supported Marketplaces

| Marketplace | Method | Region |
|---|---|---|
| **Amazon.ae** | HTML scraping | UAE |
| **Noon** | JSON API | UAE |
| **BinSina** | Algolia API | UAE |
| **Life Pharmacy** | REST API | UAE |
| **Aster** | Elasticsearch API | UAE |
| **iHerb** | HTML scraping + JSON fallback | UAE |

## Features

- **Multi-source concurrent search** â€” scrape all 6 marketplaces in parallel with a single query
- **Multi-query support** â€” search multiple terms at once using `;` as separator (e.g., `collagen;vitamin d;krill oil`)
- **Source selection** â€” toggle individual marketplaces on/off via checkboxes
- **Negative keyword filtering** â€” exclude irrelevant products using comma-separated exclusion keywords (dual-layer: pre-scrape query enhancement + post-scrape title filtering)
- **Product validation** â€” automatically drops products with empty titles or zero/negative prices
- **Deduplication** â€” removes duplicate products across sources via URL normalisation and same-source title matching, keeping the cheapest per group
- **Price comparison** â€” lowest price highlighted in bold green across all results
- **Sorting** â€” sort by price or rating with a single keypress
- **Export** â€” save results to JSON or CSV, copy to clipboard as TSV
- **Anti-detection** â€” browser-impersonating HTTP via `curl_cffi`, adaptive rate limiting, circuit breaker with auto-reset, CAPTCHA detection
- **Per-source timeout** â€” configurable request timeout per marketplace (HTML scrapers get longer timeouts than API scrapers)
- **Auto-save** â€” results automatically saved to `results/` after every search

## Installation

### Prerequisites

- Python 3.11+
- pip

### Setup

```bash
# Clone the repository
git clone <repo-url>
cd marketplace_scraper

# Create and activate a virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# .venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

### Dependencies

| Package | Purpose |
|---|---|
| `curl_cffi` | Browser-impersonating HTTP client (primary) |
| `cloudscraper` | Cloudflare bypass (fallback) |
| `beautifulsoup4` | HTML parsing |
| `lxml` | Fast HTML parser backend |
| `textual` | Terminal User Interface framework |
| `python-dotenv` | Environment variable loading |
| `pyperclip` | Clipboard operations (optional) |
| `rich` | Rich text formatting |

### Environment Variables

Create a `.env` file in the project root for any secrets or proxy configuration:

```bash
# .env (optional)
# Add proxy or API key configuration here if needed
```

## Usage

### Launch the TUI

```bash
python main.py
```

### TUI Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Header                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ðŸ›’ E-commerce Search (Noon, Amazon, BinSina, ...)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [ Search products (use ; for multiple queries)... ] â”‚
â”‚  [ Search ] â”‚
â”‚  [ Exclude keywords (comma-separated)... ]           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Sources:                                            â”‚
â”‚  [x] Noon    [x] Amazon    [x] BinSina              â”‚
â”‚  [x] Life    [x] Aster     [x] iHerb                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… Showing 42 of 78 products (36 filtered, 5 deduped, 2 invalid, saved) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Title              â”‚ Price      â”‚ Rating â”‚ Source   â”‚
â”‚  Multi Collagen ... â”‚ 89.00 AED  â”‚ â­ 4.5 â”‚ AMAZON  â”‚
â”‚  Collagen Peptid... â”‚ 95.50 AED  â”‚ â­ 4.3 â”‚ NOON    â”‚
â”‚  ...                â”‚            â”‚        â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Footer (keybindings)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Keyboard Shortcuts

| Key | Action |
|---|---|
| `Enter` | Execute search (when in search input) |
| `q` | Quit the application |
| `p` | Sort results by price (ascending) |
| `r` | Sort results by rating (descending) |
| `s` | Save results to JSON |
| `e` | Export results to CSV |
| `c` | Copy selected product URL to clipboard |
| `x` | Copy all results to clipboard (TSV format) |
| Click row | Open product URL in default browser |

### Search Workflow

1. **Type your search query** in the search input (e.g., `multi collagen peptides hyaluronic`)
   - Use `;` to search multiple terms at once: `collagen;vitamin d;krill oil`
2. **Add exclusion keywords** (optional) in the filter input, comma-separated (e.g., `serum, cream, mask, lotion, shampoo`)
3. **Toggle sources** â€” uncheck any marketplaces you want to skip
4. **Press Enter or click Search** â€” scrapers run concurrently
5. **Browse results** â€” sorted table with cheapest product highlighted; duplicates auto-removed, invalid products auto-dropped
6. **Export** â€” press `s` for JSON, `e` for CSV, `x` for clipboard

### Negative Keyword Filtering

The filter input below the search bar accepts comma-separated keywords to exclude irrelevant products. Filtering works at two levels:

**Pre-scrape (query enhancement)**
For platforms that support boolean exclusion in their search syntax (Amazon, iHerb), negative keywords are appended directly to the search query as `-keyword` terms. This reduces noise at the source and returns cleaner results.

Example: searching `collagen powder` with exclusions `serum, cream` sends `collagen powder -serum -cream` to Amazon.

**Post-scrape (title filtering)**
After results are collected from all sources, products whose titles contain any of the exclusion keywords are removed. This catches noise from API-based platforms (Noon, BinSina, Aster, Life Pharmacy) that don't support `-keyword` syntax.

The filter is case-insensitive and uses substring matching. The status bar shows how many products were filtered: `Showing X of Y products (Z filtered out)`.

**Examples by product category:**

| Searching for | Suggested exclusions |
|---|---|
| Supplements/powders | `serum, cream, mask, lotion, shampoo, conditioner, lip, gloss, balm, wash, cleanser` |
| Electronics/laptops | `case, sleeve, screen protector, sticker, skin, stand` |
| Books | `kindle, audiobook, summary, workbook` |
| Shoes | `laces, insole, cleaner, polish, tree` |

## Project Structure

```
marketplace_scraper/
â”œâ”€â”€ main.py                          # Entry point â€” launches the TUI
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .env                             # Secrets & environment config
â”œâ”€â”€ pylance.sh                       # Linter gate (Flake8 + Pyright strict)
â”œâ”€â”€ project_design.md                # Detailed design document
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ settings.py              # All constants (delays, retries, timeouts, sources)
â”‚   â”‚   â”œâ”€â”€ selectors.json           # CSS selectors for HTML-based scrapers
â”‚   â”‚   â””â”€â”€ logging_config.py        # Logging setup
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ product.py               # Product dataclass
â”‚   â”‚
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ base_scraper.py          # Abstract base: session, retries, circuit breaker
â”‚   â”‚   â”œâ”€â”€ amazon_scraper.py        # Amazon.ae (HTML)
â”‚   â”‚   â”œâ”€â”€ noon_scraper.py          # Noon (JSON API)
â”‚   â”‚   â”œâ”€â”€ binsina_scraper.py       # BinSina (Algolia API)
â”‚   â”‚   â”œâ”€â”€ life_pharmacy_scraper.py # Life Pharmacy (REST API)
â”‚   â”‚   â”œâ”€â”€ aster_scraper.py         # Aster (Elasticsearch API)
â”‚   â”‚   â””â”€â”€ iherb_scraper.py         # iHerb (HTML + JSON fallback)
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ search_orchestrator.py   # SearchOrchestrator â€” coordinates multi-source search
â”‚   â”‚
â”‚   â”œâ”€â”€ filters/
â”‚   â”‚   â”œâ”€â”€ product_filter.py        # Post-scrape filtering by negative keywords
â”‚   â”‚   â”œâ”€â”€ query_enhancer.py        # Pre-scrape query enhancement
â”‚   â”‚   â”œâ”€â”€ deduplicator.py          # URL + same-source title deduplication
â”‚   â”‚   â””â”€â”€ product_validator.py     # Drop products with empty titles / zero prices
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â””â”€â”€ file_manager.py          # JSON/CSV export, clipboard formatting
â”‚   â”‚
â”‚   â””â”€â”€ ui/
â”‚       â”œâ”€â”€ app.py                   # EcomSearchApp (Textual TUI)
â”‚       â””â”€â”€ styles.css               # TUI styles
â”‚
â”œâ”€â”€ results/                         # Auto-saved search results (JSON)
â”œâ”€â”€ logs/                            # Application logs
â””â”€â”€ tests/                           # Unit tests
```

## Architecture

### Data Flow

```
User Input (query + exclusion keywords)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SearchOrchestrator     â”‚â”€â”€â–¶ Coordinates entire pipeline
â”‚  (multi_search /        â”‚
â”‚   search)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   QueryEnhancer     â”‚â”€â”€â–¶ Appends -keywords for Amazon/iHerb
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scraper (async)    â”‚â”€â”€â”€â–¶â”‚ BaseScraper  â”‚
â”‚  â”œâ”€â”€ Amazon (20s)   â”‚    â”‚  curl_cffi   â”‚
â”‚  â”œâ”€â”€ Noon (10s)     â”‚    â”‚  cloudscraperâ”‚
â”‚  â”œâ”€â”€ BinSina (15s)  â”‚    â”‚  rate limit  â”‚
â”‚  â”œâ”€â”€ Life (10s)     â”‚    â”‚  circuit     â”‚
â”‚  â”œâ”€â”€ Aster (15s)    â”‚    â”‚  breaker +   â”‚
â”‚  â””â”€â”€ iHerb (20s)    â”‚    â”‚  cooldown    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ list[Product]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ProductValidator   â”‚â”€â”€â–¶ Drops empty titles / zero prices
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ validated list[Product]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ProductFilter     â”‚â”€â”€â–¶ Removes products matching exclusion keywords
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ filtered list[Product]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ProductDeduplicator â”‚â”€â”€â–¶ URL + same-source title dedup (keeps cheapest)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ deduplicated list[Product]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TUI (DataTable)   â”‚â”€â”€â–¶ Display, sort, highlight cheapest
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FileManager       â”‚â”€â”€â–¶ Auto-save JSON, export CSV/TSV
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Scraper Types

| Type | Scrapers | How it works |
|---|---|---|
| **HTML** | Amazon, iHerb | Fetch HTML pages, parse with BeautifulSoup + CSS selectors from `selectors.json` |
| **JSON API** | Noon, BinSina, Aster, Life Pharmacy | Call marketplace APIs directly, parse JSON responses |

### Anti-Detection Strategy

| Mechanism | Description |
|---|---|
| **Browser impersonation** | `curl_cffi` with `impersonate="chrome131"` mimics real Chrome TLS fingerprint |
| **Realistic headers** | Full set of `sec-ch-ua`, `Accept-Language`, `Referer` headers |
| **Adaptive rate limiting** | Configurable `REQUEST_DELAY` between requests, exponential backoff on failures |
| **Circuit breaker** | After `CIRCUIT_BREAKER_THRESHOLD` consecutive failures, stops hitting the source; auto-resets after `CIRCUIT_BREAKER_COOLDOWN` (60s) via half-open probe |
| **CAPTCHA detection** | Scans response HTML for CAPTCHA keywords, triggers backoff |
| **Fallback HTTP client** | If `curl_cffi` fails, falls back to `cloudscraper` |

## Configuration

All tuneable constants live in `src/config/settings.py`. No magic numbers in scraper or UI code.

| Setting | Default | Description |
|---|---|---|
| `REQUEST_DELAY` | `2.0` | Seconds between HTTP requests |
| `REQUEST_TIMEOUT` | `15` | Seconds before a request times out |
| `MAX_RETRIES` | `3` | Retry count on transient failures |
| `MAX_PAGES` | `10` | Maximum pagination depth per source |
| `CIRCUIT_BREAKER_THRESHOLD` | `3` | Consecutive failures to trip the circuit breaker |
| `CIRCUIT_BREAKER_COOLDOWN` | `60.0` | Seconds before the circuit breaker auto-resets (half-open) |
| `MAX_DELAY_MULTIPLIER` | `8` | Cap for adaptive backoff multiplier |
| `IMPERSONATE_BROWSER` | `chrome131` | Browser to impersonate in curl_cffi |
| `QUERY_ENHANCED_PLATFORMS` | `["amazon", "iherb"]` | Platforms supporting `-keyword` query syntax |

### Per-Source Timeout

Each source in `AVAILABLE_SOURCES` can optionally include a `"timeout"` key to override the global `REQUEST_TIMEOUT`. This is useful because HTML scrapers (Amazon, iHerb) need longer timeouts for page rendering, while fast REST APIs (Noon, Life Pharmacy) can use shorter timeouts:

| Source | Timeout | Reason |
|---|---|---|
| Amazon | 20s | HTML page scraping |
| iHerb | 20s | HTML + JSON hybrid |
| Noon | 10s | Fast JSON API |
| Life Pharmacy | 10s | Fast REST API |
| BinSina | 15s (default) | Algolia API |
| Aster | 15s (default) | Elasticsearch API |

### CSS Selectors

HTML-based scrapers (Amazon, iHerb) use CSS selectors defined in `src/config/selectors.json`. If a marketplace changes its layout, update the selectors file â€” not the scraper code.

```json
{
    "amazon": {
        "product_card": "div[data-component-type='s-search-result']",
        "title": "h2 span",
        "price": "span.a-price span.a-offscreen",
        "rating": "span.a-icon-alt",
        "url": "a.a-link-normal.s-line-clamp-4"
    }
}
```

## Data Model

All scrapers return a `list[Product]`. The `Product` dataclass is the single data exchange format across all modules:

```python
@dataclass
class Product:
    title: str           # Product name
    price: float         # Numeric price
    currency: str        # Default: "AED"
    rating: str          # Rating as string (e.g., "4.5 out of 5 stars")
    url: str             # Full product page URL
    source: str          # Marketplace identifier (e.g., "amazon", "noon")
    image_url: str       # Product image URL
```

## Output Formats

### JSON (auto-saved)

Results are automatically saved after every search to `results/`:

```
results/
â”œâ”€â”€ combined_multi_collagen_20260228_141532.json
â”œâ”€â”€ amazon_multi_collagen_20260228_141532.json
â”œâ”€â”€ noon_multi_collagen_20260228_141532.json
â””â”€â”€ ...
```

Each file contains an array of product objects:

```json
[
    {
        "title": "Multi Collagen Peptides Powder with Hyaluronic Acid",
        "price": 89.0,
        "currency": "AED",
        "rating": "4.5 out of 5 stars",
        "url": "https://www.amazon.ae/...",
        "source": "amazon"
    }
]
```

### CSV (on demand)

Press `e` to export a price-sorted CSV:

```csv
Title,Price,Currency,Rating,Source,URL
Multi Collagen Peptides...,89.0,AED,4.5 out of 5 stars,amazon,https://...
```

### Clipboard (on demand)

Press `x` to copy all results as tab-separated text.

## Development

### Linting

The project enforces strict code quality via `pylance.sh`:

```bash
./pylance.sh
```

This runs:
1. **Flake8** â€” style checking, max complexity 10, 88-char line limit
2. **Pyright** â€” strict mode type checking

Both must pass with zero errors before any change is considered complete.

### Adding a New Marketplace

1. Create `src/scrapers/new_scraper.py` extending `BaseScraper`
2. Implement `_get_homepage()` and `search(query: str) -> list[Product]`
3. For HTML scrapers: add CSS selectors to `src/config/selectors.json`
4. Register the source in `Settings.AVAILABLE_SOURCES`:
   ```python
   {"id": "new_source", "label": "New Source", "scraper": "src.scrapers.new_scraper.NewScraper"}
   ```
5. If the platform supports `-keyword` exclusion syntax, add its `id` to `Settings.QUERY_ENHANCED_PLATFORMS`

The TUI automatically picks up new sources â€” no UI code changes needed.

### Testing

```bash
python -m pytest tests/
```

Tests mock HTTP sessions (`curl_cffi.Session`) and never hit live marketplace URLs.

## License

Private project â€” not for redistribution.
