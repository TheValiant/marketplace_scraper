# ecom_search

A modular, local e-commerce price comparison engine for UAE markets. Search across multiple marketplaces simultaneously, filter out noise, compare prices, and export results â€” all from a rich Terminal User Interface.

> **Core Philosophy**: *"Resilience over Speed."* The engine prioritizes anti-detection and stability over raw scraping throughput.

## Supported Marketplaces

| Marketplace | Method | Region |
|---|---|---|
| **Amazon.ae** | HTML scraping | UAE |
| **Noon** | JSON API | UAE |
| **BinSina** | Algolia API | UAE |
| **Life Pharmacy** | REST API | UAE |
| **Aster** | Elasticsearch API | UAE |
| **iHerb** | HTML scraping + JSON fallback | UAE |

## Features

- **Multi-source concurrent search** â€” scrape all 6 marketplaces in parallel with a single query
- **Multi-query support** â€” search multiple terms at once using `;` as separator (e.g., `collagen;vitamin d;krill oil`)
- **Advanced boolean search** â€” combine terms with `AND`, `OR`, quoted phrases, parentheses, and inline negations (e.g., `("multi collagen" OR "types I II III") AND powder -serum -cream`)
- **Deterministic subset caching** â€” in-memory result cache with set-theoretic subset matching; repeat / narrower searches return instantly with zero network calls
- **Source selection** â€” toggle individual marketplaces on/off via checkboxes
- **Negative keyword filtering** â€” exclude irrelevant products using comma-separated exclusion keywords (dual-layer: pre-scrape query enhancement + post-scrape title filtering)
- **Product validation** â€” automatically drops products with empty titles or zero/negative prices
- **Deduplication** â€” removes duplicate products across sources via URL normalisation and same-source title matching, keeping the cheapest per group
- **Price comparison** â€” lowest price highlighted in bold green across all results
- **Sorting** â€” sort by price or rating with a single keypress
- **Export** â€” save results to JSON or CSV, copy to clipboard as TSV
- **Anti-detection** â€” browser-impersonating HTTP via `curl_cffi`, adaptive rate limiting, circuit breaker with auto-reset, CAPTCHA detection
- **Per-source timeout** â€” configurable request timeout per marketplace (HTML scrapers get longer timeouts than API scrapers)
- **Auto-save** â€” results automatically saved to `results/` after every search

## Installation

### Prerequisites

- Python 3.11+
- pip

### Setup

```bash
# Clone the repository
git clone <repo-url>
cd marketplace_scraper

# Create and activate a virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# .venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

### Dependencies

| Package | Purpose |
|---|---|
| `curl_cffi` | Browser-impersonating HTTP client (primary) |
| `cloudscraper` | Cloudflare bypass (fallback) |
| `beautifulsoup4` | HTML parsing |
| `lxml` | Fast HTML parser backend |
| `textual` | Terminal User Interface framework |
| `python-dotenv` | Environment variable loading |
| `pyperclip` | Clipboard operations (optional) |
| `rich` | Rich text formatting |

### Environment Variables

Create a `.env` file in the project root for any secrets or proxy configuration:

```bash
# .env (optional)
# Add proxy or API key configuration here if needed
```

## Usage

### Launch the TUI

```bash
python main.py
```

### TUI Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Header                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ðŸ›’ E-commerce Search (Noon, Amazon, BinSina, ...)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [ Search products (use ; for multiple queries)... ] â”‚
â”‚  [ Search ] â”‚
â”‚  [ Exclude keywords (comma-separated)... ]           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Sources:                                            â”‚
â”‚  [x] Noon    [x] Amazon    [x] BinSina              â”‚
â”‚  [x] Life    [x] Aster     [x] iHerb                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… Showing 42 of 78 products (36 filtered, 5 deduped, 2 invalid, saved) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Title              â”‚ Price      â”‚ Rating â”‚ Source   â”‚
â”‚  Multi Collagen ... â”‚ 89.00 AED  â”‚ â­ 4.5 â”‚ AMAZON  â”‚
â”‚  Collagen Peptid... â”‚ 95.50 AED  â”‚ â­ 4.3 â”‚ NOON    â”‚
â”‚  ...                â”‚            â”‚        â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Footer (keybindings)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Keyboard Shortcuts

| Key | Action |
|---|---|
| `Enter` | Execute search (when in search input) |
| `q` | Quit the application |
| `p` | Sort results by price (ascending) |
| `r` | Sort results by rating (descending) |
| `s` | Save results to JSON |
| `e` | Export results to CSV |
| `c` | Copy selected product URL to clipboard |
| `x` | Copy all results to clipboard (TSV format) |
| `i` | Invalidate (clear) the in-memory query cache |
| Click row | Open product URL in default browser |

### Search Workflow

1. **Type your search query** in the search input â€” three modes are supported:
   - **Simple**: `multi collagen peptides hyaluronic`
   - **Multi-query** (semicolons): `collagen;vitamin d;krill oil`
   - **Boolean** (auto-detected): `("multi collagen" OR "types I II III") AND powder -serum -cream`
2. **Add exclusion keywords** (optional) in the filter input, comma-separated (e.g., `serum, cream, mask, lotion, shampoo`)
3. **Toggle sources** â€” uncheck any marketplaces you want to skip
4. **Press Enter or click Search** â€” scrapers run concurrently
5. **Browse results** â€” sorted table with cheapest product highlighted; duplicates auto-removed, invalid products auto-dropped
6. **Export** â€” press `s` for JSON, `e` for CSV, `x` for clipboard

### Negative Keyword Filtering

The filter input below the search bar accepts comma-separated keywords to exclude irrelevant products. Filtering works at two levels:

**Pre-scrape (query enhancement)**
For platforms that support boolean exclusion in their search syntax (Amazon, iHerb), negative keywords are appended directly to the search query as `-keyword` terms. This reduces noise at the source and returns cleaner results.

Example: searching `collagen powder` with exclusions `serum, cream` sends `collagen powder -serum -cream` to Amazon.

**Post-scrape (title filtering)**
After results are collected from all sources, products whose titles contain any of the exclusion keywords are removed. This catches noise from API-based platforms (Noon, BinSina, Aster, Life Pharmacy) that don't support `-keyword` syntax.

The filter is case-insensitive and uses substring matching. The status bar shows how many products were filtered: `Showing X of Y products (Z filtered out)`.

**Examples by product category:**

| Searching for | Suggested exclusions |
|---|---|
| Supplements/powders | `serum, cream, mask, lotion, shampoo, conditioner, lip, gloss, balm, wash, cleanser` |
| Electronics/laptops | `case, sleeve, screen protector, sticker, skin, stand` |
| Books | `kindle, audiobook, summary, workbook` |
| Shoes | `laces, insole, cleaner, polish, tree` |

### Advanced Boolean Search

The search input supports full boolean query syntax. When the engine detects boolean operators (`AND`, `OR`, parentheses, or quoted phrases), it automatically activates the advanced pipeline.

#### Syntax Reference

| Element | Syntax | Example | Meaning |
|---|---|---|---|
| **Term** | bare word | `collagen` | Match products containing "collagen" |
| **Phrase** | `"quoted words"` | `"multi collagen"` | Match the exact phrase "multi collagen" |
| **AND** | `AND` or adjacent terms | `collagen AND powder` | Both terms must appear |
| **Implicit AND** | space-separated | `collagen powder` | Same as `collagen AND powder` |
| **OR** | `OR` | `collagen OR peptides` | Either term may appear |
| **Grouping** | `( )` | `(A OR B) AND C` | Override default precedence |
| **Negation** | `-keyword` | `-serum -cream` | Exclude products containing these words (**boolean mode only** â€” requires quotes, `AND`, `OR`, or parentheses elsewhere in the query) |

**Operator precedence** (highest to lowest): Grouping `()` > `AND` / implicit AND > `OR`

#### How It Works

1. **Parse**: The query is tokenized and parsed into an Abstract Syntax Tree (AST) using a recursive-descent parser.
2. **Extract negatives**: Trailing `-keyword` tokens are pulled out as global exclusions.
3. **DNF expansion**: The AST is converted to [Disjunctive Normal Form](https://en.wikipedia.org/wiki/Disjunctive_normal_form) (OR of ANDs). Each conjunction becomes an independent base query dispatched to the scrapers in parallel.
4. **AST verification**: After scraping, every product title is evaluated against the original AST. Products that don't logically satisfy the boolean expression are removed â€” this catches fuzzy/irrelevant results from search engines that ignore quotes or boolean operators.
5. **Negative filtering**: Products matching any `-keyword` are excluded.
6. **Deduplication**: Cross-query and cross-source duplicates are merged, keeping the cheapest.

#### Examples

**Simple OR expansion:**

```
"multi collagen" OR "hydrolyzed collagen"
```

Dispatches 2 base queries â†’ `multi collagen` and `hydrolyzed collagen` â†’ merges and deduplicates results.

**Complex boolean with negations:**

```
("multi collagen" OR "types I II III V X") AND "hyaluronic" AND powder -serum -cream -mask -gummies
```

Dispatches 2 base queries:
- `multi collagen hyaluronic powder`
- `types I II III V X hyaluronic powder`

Then locally verifies every result title contains the required phrases, and excludes any product matching `serum`, `cream`, `mask`, or `gummies`.

**Mixing with the filter input:**

In **boolean mode** (queries containing quotes, `AND`, `OR`, or parentheses), negations can appear in both places. `-keywords` embedded in the search query and comma-separated keywords in the filter input are merged. These two are equivalent:

- Search: `"multi collagen" -serum`, Filter: `cream, mask`
- Search: `"multi collagen" -serum -cream -mask`, Filter: *(empty)*

> **Note:** In simple (non-boolean) mode, `-keyword` in the search input is NOT parsed as an exclusion â€” it is sent as raw text to the search engine. Use the **filter input** for reliable exclusion on all platforms.

#### Auto-Detection

The engine auto-routes queries based on syntax:

| Query | Detected as | Pipeline |
|---|---|---|
| `collagen` | Simple | Standard `search()` |
| `collagen;vitamin d` | Multi-query | Sequential `search()` + cross-query dedup |
| `collagen -serum` | Simple | Standard `search()` â€” the `-serum` is sent as raw text; works natively on Amazon/iHerb but is **not** parsed or applied as a local filter. Use the filter input for reliable cross-platform exclusion. |
| `"multi collagen"` | Boolean (quotes) | Advanced `execute_advanced_search()` |
| `collagen AND powder` | Boolean (AND) | Advanced `execute_advanced_search()` |
| `collagen OR peptides` | Boolean (OR) | Advanced `execute_advanced_search()` |
| `(collagen OR peptides) AND powder` | Boolean (parens + operators) | Advanced `execute_advanced_search()` |

### Deterministic Subset Caching

The engine maintains an in-memory result cache that exploits set-theoretic relationships between queries to avoid redundant network calls.

#### How It Works

Every search result is cached with three keys: **base query**, **negative terms**, and **source set**. On subsequent searches, the cache checks whether an existing entry can satisfy the new request:

- A cached entry with **fewer** (or equal) negative exclusions than the requested query means the cached data is a **superset** â€” it contains everything the new query needs, plus some extra items that can be filtered locally.
- The cached entry must have the **same base query** and the **same source set** (adding a new marketplace forces a fresh scrape).

#### Subset Matching Logic

```
Cache hit when:
  cached.base_query == requested.base_query
  AND cached.source_ids == requested.source_ids
  AND cached.negative_terms âŠ† requested.negative_terms
```

#### Examples

| Step | Search | Cache State | Result |
|---|---|---|---|
| 1 | `collagen` (Amazon, Noon) | Empty | **MISS** â€” scrapes both sources, caches raw results |
| 2 | `collagen` (Amazon, Noon) | Has entry from step 1 | **HIT** â€” returns cached results instantly |
| 3 | `collagen -mask` (Amazon, Noon) | Has entry from step 1 (no negatives) | **HIT** â€” cached `{}` âŠ† requested `{mask}` â†’ filters "mask" locally |
| 4 | `collagen -mask -serum` (Amazon, Noon) | Has entry from step 1 (no negatives) | **HIT** â€” cached `{}` âŠ† `{mask, serum}` â†’ filters both locally |
| 5 | `collagen` (Amazon, Noon, iHerb) | Has entry from step 1 (Amazon, Noon only) | **MISS** â€” source set changed, re-scrapes all 3 |
| 6 | `vitamin d` (Amazon, Noon) | Has entry for "collagen" only | **MISS** â€” different base query |

Cache entries expire after `QUERY_CACHE_TTL` seconds (default: 1 hour). The cache stores results **post-validation but pre-filtering** â€” validated data (no empty titles or zero prices) but with all products intact, so narrower searches can filter locally without re-scraping.

## Project Structure

```
marketplace_scraper/
â”œâ”€â”€ main.py                          # Entry point â€” launches the TUI
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .env                             # Secrets & environment config
â”œâ”€â”€ pylance.sh                       # Linter gate (Flake8 + Pyright strict)
â”œâ”€â”€ project_design.md                # Detailed design document
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ settings.py              # All constants (delays, retries, timeouts, sources)
â”‚   â”‚   â”œâ”€â”€ selectors.json           # CSS selectors for HTML-based scrapers
â”‚   â”‚   â””â”€â”€ logging_config.py        # Logging setup
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ product.py               # Product dataclass
â”‚   â”‚
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ base_scraper.py          # Abstract base: session, retries, circuit breaker
â”‚   â”‚   â”œâ”€â”€ amazon_scraper.py        # Amazon.ae (HTML)
â”‚   â”‚   â”œâ”€â”€ noon_scraper.py          # Noon (JSON API)
â”‚   â”‚   â”œâ”€â”€ binsina_scraper.py       # BinSina (Algolia API)
â”‚   â”‚   â”œâ”€â”€ life_pharmacy_scraper.py # Life Pharmacy (REST API)
â”‚   â”‚   â”œâ”€â”€ aster_scraper.py         # Aster (Elasticsearch API)
â”‚   â”‚   â””â”€â”€ iherb_scraper.py         # iHerb (HTML + JSON fallback)
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ search_orchestrator.py   # SearchOrchestrator â€” coordinates multi-source search
â”‚   â”‚
â”‚   â”œâ”€â”€ filters/
â”‚   â”‚   â”œâ”€â”€ product_filter.py        # Post-scrape filtering by negative keywords
â”‚   â”‚   â”œâ”€â”€ query_enhancer.py        # Pre-scrape query enhancement
â”‚   â”‚   â”œâ”€â”€ query_parser.py          # Boolean query compiler (tokenizer, AST, DNF, evaluator)
â”‚   â”‚   â”œâ”€â”€ deduplicator.py          # URL + same-source title deduplication
â”‚   â”‚   â””â”€â”€ product_validator.py     # Drop products with empty titles / zero prices
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ file_manager.py          # JSON/CSV export, clipboard formatting
â”‚   â”‚   â””â”€â”€ query_cache.py           # In-memory deterministic subset cache
â”‚   â”‚
â”‚   â””â”€â”€ ui/
â”‚       â”œâ”€â”€ app.py                   # EcomSearchApp (Textual TUI)
â”‚       â””â”€â”€ styles.css               # TUI styles
â”‚
â”œâ”€â”€ results/                         # Auto-saved search results (JSON)
â”œâ”€â”€ logs/                            # Application logs
â””â”€â”€ tests/                           # Unit tests
```

## Architecture

### Data Flow

The engine supports two pipelines, selected automatically based on query syntax.

#### Standard Pipeline (simple queries, semicolon multi-queries)

```
User Input (query + exclusion keywords)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SearchOrchestrator     â”‚â”€â”€â–¶ Coordinates entire pipeline
â”‚  (multi_search /        â”‚
â”‚   search)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   QueryCache        â”‚â”€â”€â–¶ Check for subset cache hit
â”‚   (subset match?)   â”‚    HIT â†’ skip scrapers, filter locally
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    MISS â†“
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   QueryEnhancer     â”‚â”€â”€â–¶ Appends -keywords for Amazon/iHerb
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scraper (async)    â”‚â”€â”€â”€â–¶â”‚ BaseScraper  â”‚
â”‚  â”œâ”€â”€ Amazon (20s)   â”‚    â”‚  curl_cffi   â”‚
â”‚  â”œâ”€â”€ Noon (10s)     â”‚    â”‚  cloudscraperâ”‚
â”‚  â”œâ”€â”€ BinSina (15s)  â”‚    â”‚  rate limit  â”‚
â”‚  â”œâ”€â”€ Life (10s)     â”‚    â”‚  circuit     â”‚
â”‚  â”œâ”€â”€ Aster (15s)    â”‚    â”‚  breaker +   â”‚
â”‚  â””â”€â”€ iHerb (20s)    â”‚    â”‚  cooldown    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ list[Product]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ProductValidator   â”‚â”€â”€â–¶ Drops empty titles / zero prices
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ validated â†’ stored in QueryCache
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ProductFilter     â”‚â”€â”€â–¶ Removes products matching exclusion keywords
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ filtered list[Product]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ProductDeduplicator â”‚â”€â”€â–¶ URL + same-source title dedup (keeps cheapest)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ deduplicated list[Product]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TUI (DataTable)   â”‚â”€â”€â–¶ Display, sort, highlight cheapest
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FileManager       â”‚â”€â”€â–¶ Auto-save JSON, export CSV/TSV
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Advanced Pipeline (boolean queries with AND, OR, quotes, parens)

```
User Input (boolean query + exclusion keywords)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QueryPlanner.parse()   â”‚â”€â”€â–¶ Tokenize â†’ AST â†’ DNF expansion
â”‚  â”œâ”€â”€ AST                â”‚    Extracts global negatives
â”‚  â”œâ”€â”€ base_queries[]     â”‚    Produces N flat base queries
â”‚  â””â”€â”€ global_negatives   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”  (for each base query)
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Cache?  â”‚ â”‚Cache?  â”‚â”€â”€â–¶ HIT â†’ use cached results
â”‚ MISS   â”‚ â”‚  HIT   â”‚    MISS â†’ scrape via _run_scrapers()
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Results cached
â”‚  _run_scrapers()    â”‚â”€â”€â–¶ post-validation
â”‚  (QueryEnhancer +   â”‚
â”‚   concurrent scrape)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ merged list[Product]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ProductValidator   â”‚â”€â”€â–¶ Drops empty titles / zero prices
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AST Evaluator      â”‚â”€â”€â–¶ local_evaluate(title, AST)
â”‚  (local_evaluate)   â”‚    Removes products that don't satisfy
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    the boolean expression
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ProductFilter     â”‚â”€â”€â–¶ Removes products matching negatives
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ProductDeduplicator â”‚â”€â”€â–¶ Cross-query + cross-source dedup
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ final list[Product]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TUI (DataTable)   â”‚â”€â”€â–¶ Display, sort, highlight cheapest
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Scraper Types

| Type | Scrapers | How it works |
|---|---|---|
| **HTML** | Amazon, iHerb | Fetch HTML pages, parse with BeautifulSoup + CSS selectors from `selectors.json` |
| **JSON API** | Noon, BinSina, Aster, Life Pharmacy | Call marketplace APIs directly, parse JSON responses |

### Anti-Detection Strategy

| Mechanism | Description |
|---|---|
| **Browser impersonation** | `curl_cffi` with `impersonate="chrome131"` mimics real Chrome TLS fingerprint |
| **Realistic headers** | Full set of `sec-ch-ua`, `Accept-Language`, `Referer` headers |
| **Adaptive rate limiting** | Configurable `REQUEST_DELAY` between requests, exponential backoff on failures |
| **Circuit breaker** | After `CIRCUIT_BREAKER_THRESHOLD` consecutive failures, stops hitting the source; auto-resets after `CIRCUIT_BREAKER_COOLDOWN` (60s) via half-open probe |
| **CAPTCHA detection** | Scans response HTML for CAPTCHA keywords, triggers backoff |
| **Fallback HTTP client** | If `curl_cffi` fails, falls back to `cloudscraper` |

## Configuration

All tuneable constants live in `src/config/settings.py`. No magic numbers in scraper or UI code.

| Setting | Default | Description |
|---|---|---|
| `REQUEST_DELAY` | `2.0` | Seconds between HTTP requests |
| `REQUEST_TIMEOUT` | `15` | Seconds before a request times out |
| `MAX_RETRIES` | `3` | Retry count on transient failures |
| `MAX_PAGES` | `10` | Maximum pagination depth per source |
| `CIRCUIT_BREAKER_THRESHOLD` | `3` | Consecutive failures to trip the circuit breaker |
| `CIRCUIT_BREAKER_COOLDOWN` | `60.0` | Seconds before the circuit breaker auto-resets (half-open) |
| `MAX_DELAY_MULTIPLIER` | `8` | Cap for adaptive backoff multiplier |
| `IMPERSONATE_BROWSER` | `chrome131` | Browser to impersonate in curl_cffi |
| `QUERY_ENHANCED_PLATFORMS` | `["amazon", "iherb"]` | Platforms supporting `-keyword` query syntax |
| `QUERY_CACHE_TTL` | `3600.0` | In-memory result cache time-to-live (seconds) |

### Per-Source Timeout

Each source in `AVAILABLE_SOURCES` can optionally include a `"timeout"` key to override the global `REQUEST_TIMEOUT`. This is useful because HTML scrapers (Amazon, iHerb) need longer timeouts for page rendering, while fast REST APIs (Noon, Life Pharmacy) can use shorter timeouts:

| Source | Timeout | Reason |
|---|---|---|
| Amazon | 20s | HTML page scraping |
| iHerb | 20s | HTML + JSON hybrid |
| Noon | 10s | Fast JSON API |
| Life Pharmacy | 10s | Fast REST API |
| BinSina | 15s (default) | Algolia API |
| Aster | 15s (default) | Elasticsearch API |

### CSS Selectors

HTML-based scrapers (Amazon, iHerb) use CSS selectors defined in `src/config/selectors.json`. If a marketplace changes its layout, update the selectors file â€” not the scraper code.

```json
{
    "amazon": {
        "product_card": "div[data-component-type='s-search-result']",
        "title": "h2 span",
        "price": "span.a-price span.a-offscreen",
        "rating": "span.a-icon-alt",
        "url": "a.a-link-normal.s-line-clamp-4"
    }
}
```

## Data Model

All scrapers return a `list[Product]`. The `Product` dataclass is the single data exchange format across all modules:

```python
@dataclass
class Product:
    title: str           # Product name
    price: float         # Numeric price
    currency: str        # Default: "AED"
    rating: str          # Rating as string (e.g., "4.5 out of 5 stars")
    url: str             # Full product page URL
    source: str          # Marketplace identifier (e.g., "amazon", "noon")
    image_url: str       # Product image URL
```

## Output Formats

### JSON (auto-saved)

Results are automatically saved after every search to `results/`:

```
results/
â”œâ”€â”€ combined_multi_collagen_20260228_141532.json
â”œâ”€â”€ amazon_multi_collagen_20260228_141532.json
â”œâ”€â”€ noon_multi_collagen_20260228_141532.json
â””â”€â”€ ...
```

Each file contains an array of product objects:

```json
[
    {
        "title": "Multi Collagen Peptides Powder with Hyaluronic Acid",
        "price": 89.0,
        "currency": "AED",
        "rating": "4.5 out of 5 stars",
        "url": "https://www.amazon.ae/...",
        "source": "amazon"
    }
]
```

### CSV (on demand)

Press `e` to export a price-sorted CSV:

```csv
Title,Price,Currency,Rating,Source,URL
Multi Collagen Peptides...,89.0,AED,4.5 out of 5 stars,amazon,https://...
```

### Clipboard (on demand)

Press `x` to copy all results as tab-separated text.

## Development

### Linting

The project enforces strict code quality via `pylance.sh`:

```bash
./pylance.sh
```

This runs:
1. **Flake8** â€” style checking, max complexity 10, 88-char line limit
2. **Pyright** â€” strict mode type checking

Both must pass with zero errors before any change is considered complete.

### Adding a New Marketplace

1. Create `src/scrapers/new_scraper.py` extending `BaseScraper`
2. Implement `_get_homepage()` and `search(query: str) -> list[Product]`
3. For HTML scrapers: add CSS selectors to `src/config/selectors.json`
4. Register the source in `Settings.AVAILABLE_SOURCES`:
   ```python
   {"id": "new_source", "label": "New Source", "scraper": "src.scrapers.new_scraper.NewScraper"}
   ```
5. If the platform supports `-keyword` exclusion syntax, add its `id` to `Settings.QUERY_ENHANCED_PLATFORMS`

The TUI automatically picks up new sources â€” no UI code changes needed.

### Testing

```bash
python -m pytest tests/
```

Tests mock HTTP sessions (`curl_cffi.Session`) and never hit live marketplace URLs.

## License

Private project â€” not for redistribution.
